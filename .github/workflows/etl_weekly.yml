# .github/workflows/etl_weekly.yml
name: ETL weekly
on: { schedule: [ { cron: "0 9 * * MON" } ], workflow_dispatch: {} }
jobs:
  run-etl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.12" }
      - name: Show repo and requirements
        run: |
          pwd; ls -la
          echo "---- requirements.txt ----"
          sed -n '1,120p' requirements.txt || true
          echo "---- end requirements.txt ----"
      - name: Install deps
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip setuptools wheel
          python -m pip install --no-cache-dir -r "$GITHUB_WORKSPACE/requirements.txt"
          python -m pip show google-cloud-bigquery
          python - <<'PY'
          import pkgutil, sys
          mods = [m.name for m in pkgutil.iter_modules() if m.name.startswith('google')]
          print("google namespace mods:", mods)
          __import__('google.cloud.bigquery')
          print('bigquery import ok')
          PY
      - name: Auth
        env: 
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
        run: |
          echo "$GCP_SA_JSON" > /tmp/gcp.json
          export GCR_ETL_SCHEDULER_CREDS=/tmp/gcp.json
          echo "GCR_ETL_SCHEDULER_CREDS=/tmp/gcp.json" >> $GITHUB_ENV
      - name: Run ETL
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          BQ_PROJECT_ID: ${{ secrets.BQ_PROJECT_ID }}
        run: python etl.py --resume
